Наконец приступим к практической части. Для передачи сообщений используется процедура **MPI_Send**. Эта процедура осуществляет передачу сообщения с блокировкой. Синтаксис у нее следующий:

```cpp
int MPI_Send(void* buf, int count, MPI_Datatype datatype, int dest, 						 int msgtag, MPI_Comm comm);
```

Что тут есть что:  
**buf** - ссылка на адрес по которому лежат данные, которые мы пересылаем. В случае массивов ссылка на первый элемент.  
**count** - количество элементов в этом массиве, если отправляем просто переменную, то пишем 1.  
**datatype** - тут уже чутка посложнее, у _[[MPI]]_ есть свои переопределенные типы данных которые существуют в _С++_. Их таблицу я приведу чуть дальше.  
**dest** - номер процесса кому отправляем сообщения.  
**msgtag** - _ID_ сообщения (любое целое число)  
**comm** - Коммуникатор в котором находится процесс которому мы отправляем сообщение.

А вот как называются основные стандартные типы данных С++ определенные в **MPI_Datatype**:

|   |   |
|---|---|
|**Название в MPI**|**Тип даных в С++**|
|MPI_CHAR|char|
|MPI_SHORT|signed short|
|MPI_INT|signed int|
|MPI_LONG|signed long int|
|MPI_LONG_LONG|signed long long int|
|MPI_UNSIGNED__***_ (Вместо *** int и т.п.)|unsigned ...|
|MPI_FLOAT|float|
|MPI_DOUBLE|double|
|MPI_LONG___DOUBLE|long double|
|MPI_INT8_T|int8_t|
|MPI_INT16___T|int16_t|
|MPI_C___COMPLEX|float _Complex|

Аналогичным способом указываются и другие типы данных определенные в стандартной библиотеке С/С++ - MPI_\[Через _ в верхнем регистре пишем тип так как он назван в С\]. Еще один пример для закрепления понимания, есть тип беззнаковых 32 битных целых чисел, назван он **uint32_t**, чтобы получить этот тип данных переопределенным в _MPI_ необходимо написать следующую конструкцию: **MPI_UINT32_T**. То есть все вполне логично и легко, верхний регистр, вместо пробелов знаки андерскора и в начале пишем _MPI_.

Блокировка защитит пересылаемые данные от изменений поэтому не стоит опасаться за корретность отправленных данных, после того как коммуникация завершится и выполнится какое либо условие, то процесс спокойно продолжит заниматься своими делами.

Теперь поговорим о приеме этих сообщений. Для этого в _MPI_ определена процедура **MPI_Recv**. Она осуществляет, соответственно, блокирующий прием данных. Синтаксис выглядит вот так:

```cpp
int MPI_Recv(void* buf, int count, MPI_Datatype datatype, int source,						 int tag, MPI_Comm comm, MPI_Status* status);
```

Что тут есть что:  
**buf** - ссылка на адрес по которому будут сохранены передаваемые данные.  
**count** - максимальное количество принимаемых элементов.  
**datatype** - тип данных переопределенный в _MPI_(по аналогии с _Send_).  
**source** - номер процесса который отправил сообщение.  
**tag** - _ID_ сообщения которое мы принимаем (любое целое число)  
**comm** - Коммуникатор в котором находится процесс от которого получаем сообщение.  
**status** - структура, определенная в _MPI_ которая хранит информацию о пересылке и статус ее завершения.

Тут все практически идентично процедуре Send, только появился аргумент статуса пересылки. Зачем он нужен? Не всегда нужно явно указывать от какого процесса приходит сообщение, какой тег сообщения мы принимаем, чтобы избавиться от неопределенности _MPI_ сохраняет информацию которая не указана в процессе-преемнике явно и мы можем к ней обратиться. Например чтобы узнать процесс который отправил сообщение и тэг этого сообщения:

```cpp
	MPI_Status status;
	MPI_Recv(&buffer, 1, MPI_Float, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &status)
	tag = status.MPI_SOURCE
	source = status.MPI_SOURCE
```

Здесь представлен кусочек возможного кода в процессе который принимает данные не более одного float элемента от любого процесса с любым тегом сообщения. Чтобы узнать какой процесс прислал это сообщение и с каким тэгом нужно собственно воспользоваться структурой **MPI_Status**.

Заметим появление констант **MPI_ANY_SOURCE** и **MPI_ANY_TAG**, они явно указывают, что можно принимать сообщения от любого процесса с любым тэгом.

Дабы закрепить знания об этих двух процедурах приведу пример как это выглядит на практике, данная программа определяет простые числа на заданном интервале:

```cpp
#include <stdio.h>
#include <time.h>
#include "mpi.h"

#define RETURN return 0
#define FIRST_THREAD 0

int* get_interval(int, int, int*);
inline void print_simple_range(int, int);
void wait(int);

int main(int argc, char **argv) {	
	// инициализируем необходимые переменные	
	int thread, thread_size, processor_name_length;	
	int* thread_range, interval;	
	double cpu_time_start, cpu_time_fini;	
	char* processor_name = new char[MPI_MAX_PROCESSOR_NAME * sizeof(char)];	
	
	MPI_Status status;	
	interval = new int[2];
			
	// Инициализируем работу MPI	
	MPI_Init(&argc, &argv);	
		
	// Получаем имя физического процессора	
	MPI_Get_processor_name(processor_name, &processor_name_length);
			
	// Получаем номер конкретного процесса на котором запущена программа	
	MPI_Comm_rank(MPI_COMM_WORLD, &thread);	
		
	// Получаем количество запущенных процессов	
	MPI_Comm_size(MPI_COMM_WORLD, &thread_size);
			
	// Если это первый процесс, то выполняем следующий участок кода	
	if(thread == FIRST_THREAD)	{		
		// Выводим информацию о запуске		
		printf("----- Programm information -----\n");		
		printf(">>> Processor: %s\n", processor_name);		
		printf(">>> Num threads: %d\n", thread_size);		
		printf(">>> Input the interval: ");		
		// Просим пользователья ввести интервал на котором будут вычисления		
		scanf("%d %d", &interval[0], &interval[1]);		
		// Каждому процессу отправляем полученный интервал с тегом сообщения 0. 		
		for (int to_thread = 1; to_thread < thread_size; to_thread++)       
		MPI_Send(&interval, 2, MPI_INT, to_thread, 0, MPI_COMM_WORLD);		
		// Начинаем считать время выполнения		
		cpu_time_start = MPI_Wtime();
			
	} else {
	// Если процесс не первый, тогда ожидаем получения данных	
		MPI_Recv(&interval, 2, MPI_INT, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &status);	
	}
	
	// Все процессы запрашивают свой интервал	
	range = get_interval(thread, thread_size, interval);	
	
	// После чего отправляют полученный интервал в функцию которая производит вычисления	
	print_simple_range(range[0], range[1]);	
	// Последний процесс фиксирует время завершения, ожидает 1 секунду и выводит результат	
	
	if(thread == thread_size - 1)	{		
		cpu_time_fini = MPI_Wtime();		
		wait(1);		
		printf("CPU Time: %lf ms\n", (cpu_time_fini - cpu_time_start) * 1000);	
	}	
	MPI_Finalize();	
	RETURN;
}

// Функция для рассчета интервала каждого процесса	
int* get_interval(int proc, int size, int interval){	
	int* range = new int[2];	
	int interval_size = (interval[1] - interval[0]) / size;	
	
	range[0] = interval[0] + interval_size * proc;	
	range[1] = interval[0] + interval_size * (proc + 1);	
	range[1] = range[1] == interval[1] - 1 ? interval[1] : range[1];	
	return range;
}

inline void print_simple_range(int ibeg, int iend){	
	// Прострейшая реализация определения простого числа	
	bool res;	
	for(int i = ibeg; i <= iend; i++)	{		
		res = true;		
		while(res)		
		{			
			res = false;			
			for(int j = 2; j < i; j++) if(i % j == 0)  res = true;			
			if(res) break;		
		}		
		res = not res;		
		if(res) printf("Simple value ---> %d\n", i);	
	}
}

void wait(int seconds) { 	
	// Функция ожидающая в течение seconds секунд	
	clock_t endwait;	
	endwait = clock () + seconds * CLOCKS_PER_SEC ;	
	while (clock() < endwait) {
	
	};
}
```

Поясню основные моменты и идею. Здесь передача сообщений задействована дабы остановить все процессы кроме первого до того момента пока пользователь не введет необходимые данные. Как только мы вводим требуемый интервал для вычисления, то процессы получают эту информацию от того потока, который занимался ее сбором и начинают свою работу независимо. В конце последний процесс фиксирует время вычислений, ожидает одну секунду(дабы остальные уж точно завершили за это время свою работу) и выводит результат расчета времени. Почему же именно последний?  
Нужно учитывать тот факт, что интервал который приходит от пользователя разбивается на N равных частей, а значит последнему процессу достанется часть с самыми большими числами, вследствие вычисления займут наибольшее время именно в нем, а значит и программа в худшем случае отработает именно за это время.