Чтобы выполнять полезные действия при построении параллельной программы необходимо распределять роли между вычислительными узлами, потоками. Для этого нам просто жизненно необходимо знать какой поток обрабатывает конкретный экземпляр запущенной на нем программы, но для начала неплохо было бы узнать сколько их запущено вообще.

Для того чтобы узнать на каком потоке запущена программа существует процедура **MPI_Comm_size**. Она принимает на вход [[Коммуникатор]] (о нем пойдет речь далее), и **адрес памяти куда будет записано целое число**, то есть **количество потоков** обрабатывающих программу.

```cpp
int MPI_Comm_size(MPI_Comm comm, int* size)
```

Так что такое коммуникатор и зачем он собственно нужен? _[[Коммуникатор]]_ это такой объект, который хранит в себе информацию о запущенных потоках, доступ к которым ему предоставлен. Роль коммуникатора в программе очень важна, так как большая часть работы с процессами связана именно через него, на то он и называется коммуникатором. В _[[MPI]]_ существует глобальный коммуникатор который имеет доступ ко всем запущенным потокам, его название **MPI_COMM_WORLD**. Также мы можем создавать свои, локальные коммуникаторы для выполнения определенных задач на конкретных потоках, и это довольно мило.

Что такое коммуникатор разобрались, теперь было бы неплохо узнать на каком из процессов работает конкретный экземпляр программы. Для этого существует процедура **MPI_Comm_rank**. Она принимает на вход аналогичные параметры, только вместо сохранения количества процессов она сохраняет по адресу номер конкретного процесса. Определена она вот так:

```cpp
int MPI_comm_rank(MPI_Comm comm, int* rank)
```

То есть мы передаем ей **коммуникатор** в котором надо узнать номер процесса и собственно **адрес куда его нужно записать**.

Теперь предлагаю соединить эти 2 важные процедуры и посмотреть на их работу на практике, пока еще конечно на бесполезной программе, но понять как работают эти процедуры она позволит вполне.

```cpp

#include <stdio.h>
#include "mpi.h"

int main(int argc, char **argv) {
	int rank, size;	
	MPI_Init(&argc, &argv);
	MPI_Comm_size(MPI_COMM_WORLD, &size);
	MPI_Comm_rank(MPI_COMM_WORLD, &rank);	  
	MPI_Finalize();  	
	printf("Process: %d, size: %d\n", rank, size);		
	return 0;
}

```

Выход для 5 потоков будет следующим:

```
Process: 0, size: 5
Process: 1, size: 5
Process: 2, size: 5
Process: 3, size: 5
Process: 4, size: 5
```

Как видим каждый поток напечатал свой номер процесса и общее число запущенных процессов.

Как это можно использовать? Я думаю вы уже догадались, что уже имея только эту информацию можно использовать возможности параллельного выполнения программы. Допустим у нас есть задача где довольно много однотипных независимых вычислений, будь то сложение, вычитание матриц, векторов, возведение в степень большого числа чисел и т.п. То есть те задачи, где вычисления никак не зависят друг от друга.